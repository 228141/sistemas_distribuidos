<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Aula 02</title>
</head>
<body>
    <h1>Sistemas Concorrentes</h1>

    <h2>Introdução</h2>
        <p>Os sistemas concorrentes têm como origem a existência de vários processos ou threads executados de forma colaborativa para uma mesma tarefa, sendo que os sistemas nos quais estão inseridos podem conter um único processador ou múltiplos processadores. No caso de um único processador, os processos se revezam conforme os parâmetros de escalonamento estabelecidos pelo sistema operacional. E, no caso de múltiplos processadores, as tarefas podem ser executadas em vários processadores, com cada tarefa sendo executada em um processador diferente. Evidentemente, em sistemas concorrentes, deve ocorrer o compartilhamento de recursos. Por isso, os processos concorrentes precisam ser sincronizados para garantir a sua correta interpretação e evitar problemas na aplicação.</p>
        <p>O objetivo deste capítulo é apresentar os sistemas concorrentes e demonstrar como funciona o compartilhamento de recursos, o uso de processos e threads, além da implementação de controles para as regiões críticas por mecanismos de exclusão mútua, mutex e semáforo.</p>
    
    <h2>1. Os sistemas concorrentes e a memória compartilhada</h2>
        <p>Dentro do ambiente de sistemas distribuídos, os aplicativos fornecem recursos que são compartilhados pelos usuários, e dessa forma pode ocorrer acesso concomitante ao recurso compartilhado. A estratégia de aceitar um pedido de cliente por vez limita o funcionamento do sistema, e, portanto, a permissão para que vários pedidos de clientes sejam processados concorrentemente se torna a melhor estratégia. Para que se tenha sucesso nessa operação, é necessário que o processo em um sistema distribuído seja responsável por garantir a operação correta em um ambiente concorrente, obedecendo aos critérios de compartilhamento. O gerenciamento e a operação do uso concorrente podem ser realizados utilizando-se semáforos e locks, que estão disponíveis nos sistemas operacionais. Caso esses critérios não sejam seguidos, poderá ocorrer inconsistência nos dados (COULOURIS; DOLLIMORE; KINDBERG, 2007). e Van Steen (2008) informam que as aplicações concorrentes podem usar diversos métodos de comunicação. Um dos exemplos é o uso de memória compartilhada entre os processos ou através da troca de mensagens entre processos em execução.</p>
        <p>A memória compartilhada é um mecanismo de comunicação utilizado através de um buffer, que é compartilhado entre os processos para as operações de escrita e leitura, e na operação de escrita o processo grava dados no buffer somente quando este estiver vazio. Já na operação de leitura, um processo lê dados no buffer quando existe algo. A sincronização é o mecanismo que coloca os processos para aguardar a sua execução, evitando conflitos (MACHADO; MAIA, 2017).</p>
        <p>A figura 1 ilustra esse comportamento. No lado esquerdo, temos o processo escrita, e no lado direito o processo leitura. Entre os processos escrita e leitura há uma seta bidirecional que realiza o sincronismo entre a escrita e a leitura. Abaixo dos dois processos, há a representação do buffer recebendo a entrada de dados do processo escrita e da saída dos dados para o processo leitura.</p>
        <p>Os processos concorrentes devem se comunicar ao realizar qualquer atividade no conteúdo da memória compartilhada através de estratégias bem definidas. Entre essas estratégias, destacam-se exclusão mútua, semáforo e gerenciamento (LYNCH, 1996). Para alcançar esse objetivo, as linguagens de programação devem prover suporte para a concorrência. Um dos exemplos é a linguagem de programação Python, que utiliza o modelo de memória compartilhada com o bloqueio de acesso realizado por monitores.</p>
        <p>Na prática</p>
        <p>O website do Vale Lab 4, da Universidade da Califórnia, disponibiliza um artigo intitulado “Sharing memory between processes”, tratando do compartilhamento de memória entre processos. Neste site há uma explicação teórica sobre o assunto e também uma prática para a criação de segmentos de memória para serem compartilhados entre processos em linguagem C.</p>
    
    <h2>2. Uso de processos e threads</h2>
        <p>Com a evolução dos sistemas, a forma tradicional de um processo, executado em um único fluxo, tornou-se insuficiente para o compartilhamento de recursos entre atividades relacionadas. Uma nova solução foi proposta aprimorando-se a noção de processo e associando múltiplas atividades (threads), para que assim fosse possível ocorrer a distribuição do processamento e a tarefa não precisasse mais ser sequencial.</p>
        <p>Na figura 2, é possível visualizar a execução sequencial de um processo, ficando o processador, a memória e os demais recursos computacionais alocados de forma dedicada até o final da tarefa. A figura 2 é descrita com três itens: processo, execução e término. O passo 1 é o início do processo, com a alocação dos recursos; já o passo 2 é a execução do processo, ficando todos os recursos alocados até que o processo seja finalizado; e, finalmente, no passo 3 ocorre o término da execução do processo.</p>
        <p>A Figura 2 apresenta três itens, dispostos em sequência de forma linear representando os passos da execução sequencial de um processo. São eles: 1 - processo, 2- execução e 3 -término.
        Figura 2 – Fluxo linear</p>
        <p>Já as threads são criadas dentro de processos, e os processos possuem no mínimo uma linha de execução, conforme é ilustrado na figura 3. Na imagem, temos um único processo com três threads, sendo cada thread associada a um processador e ocorrendo o processamento simultâneo.</p>
        <p>A Figura 3 apresenta um círculo grande nomeado como processo, e dentro deste círculo têm três círculos menores identificados como Thread 1, Thread 2 e Thread 3, respectivamente. Em cada círculo menor tem uma linha que conecta em um quadrado. Os quadrados estão identificados como CPU 1, CPU 2 e CPU 3.</p>
        <p>Figura 3 – Threads</p>
        <p>Para elucidar o conceito de processos e threads, vejamos esta analogia feita por Coulouris, Dollimore e Kindberg (2007):</p>
        <p>Um ambiente de execução consiste em um jarro tampado com ar e o alimento dentro dele. Inicialmente há uma mosca – uma thread – no jarro. Essa mosca, assim como suas descendentes, pode produzir outras moscas e matá-las. Qualquer mosca pode consumir qualquer recurso (ar ou alimento) no jarro. As moscas podem ser programadas para entrarem em uma fila, de maneira ordenada, para consumir recursos. Se não tiverem essa disciplina, elas podem se chocar umas com as outras dentro do jarro – isto é, colidir e produzir resultados imprevisíveis ao tentarem consumir os mesmos recursos de maneira não controlada. As moscas podem se comunicar com (enviar mensagens para) moscas de outros jarros, mas nenhuma pode escapar do jarro e nenhuma mosca de fora pode entrar nele.(COULOURIS; DOLLIMORE; KINDBERG, 2007, p. 206)</p>
        <p>CONTINUE</p>
    
    
    <h2>3. Implementação de mutex e semáforo</h2>

</body>
</html>